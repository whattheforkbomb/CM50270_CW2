{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07431507-7963-404c-b6e1-c8c6a3261e7f",
   "metadata": {},
   "source": [
    "# A2C Demo\n",
    "This notebook focuses on training and testing the Advantage Actor-Critic (A2C) algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edde6b0c-f316-4730-8b8c-b3d9f58fa455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2c.agent import A2CAgent\n",
    "from a2c.model import ACNetwork\n",
    "from utils.wrappers import ResizeObservation, SkipFrame\n",
    "from utils.config import Config\n",
    "from utils.helper import get_primary_device\n",
    "\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "from gym.wrappers import FrameStack, GrayScaleObservation\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b44f35-ebcd-4272-a02e-092430cf4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "ENV_NAME = 'SuperMarioBros-v3'\n",
    "\n",
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 0.001\n",
    "EPSILON = 1e-3\n",
    "ENTROPY_WEIGHT = 0.01\n",
    "VALUE_LOSS_WEIGHT = 1.0\n",
    "\n",
    "N_STEPS = 10 # TD bootstrapping\n",
    "GRAD_CLIP = 0.1 # Prevents gradients from being too large\n",
    "NUM_EPISODES = 2000\n",
    "\n",
    "# Create environment\n",
    "env = gym_super_mario_bros.make(ENV_NAME)\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "\n",
    "# Apply wrappers to environment\n",
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env, keep_dim=False) # Grayscale images\n",
    "env = ResizeObservation(env, shape=84) # image dim: [84, 84]\n",
    "env = FrameStack(env, num_stack=4) # 4 frames at a time\n",
    "\n",
    "# Set config instance\n",
    "config = Config(env=env, env_name=ENV_NAME)\n",
    "\n",
    "# Create network and optimizer\n",
    "network = ACNetwork(config.input_shape, config.n_actions)\n",
    "optimizer = optim.Adam(network.parameters(), lr=LEARNING_RATE, eps=EPSILON)\n",
    "\n",
    "# Add hyperparameters to config\n",
    "config.add(\n",
    "    discount=GAMMA,\n",
    "    entropy_weight=ENTROPY_WEIGHT,\n",
    "    value_loss_weight=VALUE_LOSS_WEIGHT,\n",
    "    rollout_size=N_STEPS,\n",
    "    grad_clip=GRAD_CLIP,\n",
    "    num_episodes=NUM_EPISODES,\n",
    "    network=network,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc1be70a-ef84-46cd-8983-dfe7baccd52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available actions: Discrete(5)\n",
      "Obs space shape:  (4, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/Kautenja/gym-super-mario-bros/blob/master/gym_super_mario_bros/actions.py\n",
    "print('Available actions:', config.action_space)\n",
    "print('Obs space shape: ', config.input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200f45d2-796e-4ed3-8d47-0bf2fc96c42a",
   "metadata": {},
   "source": [
    "# Training\n",
    "This section focus on training the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b91a75-fa48-4032-a822-ea70e585c9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training with rollout length 2 on 2000 episodes.\n",
      "(1/2K) Episode avg return: -0.033\tEpisode total loss: -0.015\tAccumulated batch total avg return: -0.033\n",
      "(100/2K) Episode avg return: 64.981\tEpisode total loss: 0.333\tAccumulated batch total avg return: 3290.875\n",
      "(200/2K) Episode avg return: 67.050\tEpisode total loss: 0.057\tAccumulated batch total avg return: 9937.418\n",
      "(300/2K) Episode avg return: 65.894\tEpisode total loss: 0.055\tAccumulated batch total avg return: 16579.330\n",
      "(400/2K) Episode avg return: 67.828\tEpisode total loss: 0.058\tAccumulated batch total avg return: 23273.279\n",
      "(500/2K) Episode avg return: 66.035\tEpisode total loss: 0.055\tAccumulated batch total avg return: 29968.782\n",
      "(600/2K) Episode avg return: 65.775\tEpisode total loss: 0.055\tAccumulated batch total avg return: 36632.279\n",
      "(700/2K) Episode avg return: 67.798\tEpisode total loss: 0.058\tAccumulated batch total avg return: 43290.924\n",
      "(800/2K) Episode avg return: 68.130\tEpisode total loss: 0.059\tAccumulated batch total avg return: 49961.600\n",
      "(900/2K) Episode avg return: 67.443\tEpisode total loss: 0.058\tAccumulated batch total avg return: 56629.637\n",
      "(1.0K/2K) Episode avg return: 67.560\tEpisode total loss: 0.058\tAccumulated batch total avg return: 63325.775\n",
      "Saved model at episode 1000 as: 'a2c_rollout2_ep1k'.\n",
      "  Batch total avg return: 63325.775\n",
      "  Batch avg total loss: 0.117\n",
      "(1.1K/2K) Episode avg return: 65.187\tEpisode total loss: 0.054\tAccumulated batch total avg return: 6630.229\n",
      "(1.2K/2K) Episode avg return: 67.563\tEpisode total loss: 0.058\tAccumulated batch total avg return: 13247.853\n",
      "(1.3K/2K) Episode avg return: 65.878\tEpisode total loss: 0.055\tAccumulated batch total avg return: 19887.257\n",
      "(1.4K/2K) Episode avg return: 65.904\tEpisode total loss: 0.055\tAccumulated batch total avg return: 26554.878\n",
      "(1.5K/2K) Episode avg return: 68.284\tEpisode total loss: 0.059\tAccumulated batch total avg return: 33244.295\n",
      "(1.6K/2K) Episode avg return: 66.257\tEpisode total loss: 0.055\tAccumulated batch total avg return: 39944.134\n",
      "(1.7K/2K) Episode avg return: 65.618\tEpisode total loss: 0.054\tAccumulated batch total avg return: 46579.471\n",
      "(1.8K/2K) Episode avg return: 67.980\tEpisode total loss: 0.059\tAccumulated batch total avg return: 53239.668\n",
      "(1.9K/2K) Episode avg return: 66.295\tEpisode total loss: 0.055\tAccumulated batch total avg return: 59921.013\n",
      "(2.0K/2K) Episode avg return: 67.821\tEpisode total loss: 0.058\tAccumulated batch total avg return: 66563.117\n",
      "Saved model at episode 2000 as: 'a2c_rollout2_ep2k'.\n",
      "  Batch total avg return: 66563.117\n",
      "  Batch avg total loss: 0.056\n"
     ]
    }
   ],
   "source": [
    "# Train agent\n",
    "agent.tuning(config=config, rollout_sizes=[2], print_every=100, save_count=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3920c731-18da-4439-81b7-fa54455d2805",
   "metadata": {},
   "source": [
    "## Testing\n",
    "This section focuses on testing and analysing the models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "020e4a44-5431-458c-8f30-7c54c907e2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single CUDA device available. Device set to GPU.\n"
     ]
    }
   ],
   "source": [
    "filename = ?\n",
    "\n",
    "# Get device name\n",
    "device_count = torch.cuda.device_count()\n",
    "device = get_primary_device(count=device_count)\n",
    "\n",
    "# Create agent instance\n",
    "agent = A2CAgent(config=config, device=device)\n",
    "\n",
    "# Load pretrained model\n",
    "agent.load_model(filename=filename, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b87e4a0-e60d-4058-a83e-50ce965f499c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ep_range': [1, 1000],\n",
       "  'avg_return': 63325.77533905105,\n",
       "  'avg_total_loss': 0.11705259360513708},\n",
       " {'ep_range': [1001, 2000],\n",
       "  'avg_return': 66563.1174833184,\n",
       "  'avg_total_loss': 0.056180228027690654}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.logger.save_batch_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be96230-ba0c-46b9-a29f-01e31bee859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plotter\n",
    "vis = Plotter(logger=agent.logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b447f932-ced8-4d9e-90e9-27b13d7a35fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select method for watching the agent play the environment\n",
    "vis.video_render(env=env, agent=agent, steps=3000)\n",
    "# vis.plot_render(env=env, agent=agent, steps=3000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rla2",
   "language": "python",
   "name": "rla2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
