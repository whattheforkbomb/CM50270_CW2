{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07431507-7963-404c-b6e1-c8c6a3261e7f",
   "metadata": {},
   "source": [
    "# A2C Demo\n",
    "This notebook focuses on training and testing the Advantage Actor-Critic (A2C) algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edde6b0c-f316-4730-8b8c-b3d9f58fa455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2c.agent import A2CAgent\n",
    "from a2c.model import ACNetwork\n",
    "from utils.wrappers import ResizeObservation, SkipFrame\n",
    "from utils.config import Config\n",
    "from utils.helper import set_device\n",
    "\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import RIGHT_ONLY\n",
    "from gym.wrappers import FrameStack, GrayScaleObservation\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3b44f35-ebcd-4272-a02e-092430cf4c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available. Device set to GPU.\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters\n",
    "ENV_NAME = 'SuperMarioBros-v3'\n",
    "\n",
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 0.001\n",
    "EPSILON = 1e-3\n",
    "ENTROPY_WEIGHT = 0.01\n",
    "VALUE_LOSS_WEIGHT = 1.0\n",
    "\n",
    "N_STEPS = 10 # TD bootstrapping\n",
    "GRAD_CLIP = 0.1 # Prevents gradients from being too large\n",
    "NUM_EPISODES = 1000\n",
    "\n",
    "# Create environment\n",
    "env = gym_super_mario_bros.make(ENV_NAME)\n",
    "env = JoypadSpace(env, RIGHT_ONLY)\n",
    "\n",
    "# Apply wrappers to environment\n",
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env, keep_dim=False) # Grayscale images\n",
    "env = ResizeObservation(env, shape=84) # image dim: [84, 84]\n",
    "env = FrameStack(env, num_stack=4) # 4 frames at a time\n",
    "\n",
    "# Set config instance\n",
    "config = Config()\n",
    "\n",
    "# Set cuda device\n",
    "device = set_device()\n",
    "\n",
    "# Add core items to config\n",
    "config.add(\n",
    "    env=env,\n",
    "    env_name=ENV_NAME,\n",
    "    discount=GAMMA,\n",
    "    entropy_weight=ENTROPY_WEIGHT,\n",
    "    value_loss_weight=VALUE_LOSS_WEIGHT,\n",
    "    rollout_size=N_STEPS,\n",
    "    grad_clip=GRAD_CLIP,\n",
    "    device=device,\n",
    "    num_episodes=NUM_EPISODES\n",
    ")\n",
    "\n",
    "# Setup environment parameters\n",
    "config.set_env_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc1be70a-ef84-46cd-8983-dfe7baccd52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available actions: Discrete(5)\n",
      "Obs space shape:  (4, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/Kautenja/gym-super-mario-bros/blob/master/gym_super_mario_bros/actions.py\n",
    "print('Available actions:', config.action_space)\n",
    "print('Obs space shape: ', config.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19b73843-b9ee-40dd-9097-8f937bbe4018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create networks\n",
    "network = ACNetwork(config.input_shape, config.n_actions).to(device)\n",
    "\n",
    "# Add networks and optimizers to config\n",
    "config.add(\n",
    "    network=network,\n",
    "    optimizer = optim.Adam(network.parameters(), lr=LEARNING_RATE, eps=EPSILON)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf564bc8-ee7a-49c3-be99-3ff284dcd259",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = A2CAgent(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b91a75-fa48-4032-a822-ea70e585c9dc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training with rollout length 10.\n",
      "(1/1000) Episode actions: [3, 3, 3, 4, 4, 2, 3, 0, 3, 2]\tAvg return: 5.192\tTotal loss: 25.497\n",
      "(100/1000) Episode actions: [3, 3, 3, 3, 3, 3, 1, 3, 3, 3]\tAvg return: 95.496\tTotal loss: 0.001\n",
      "(200/1000) Episode actions: [1, 4, 4, 4, 1, 4, 1, 4, 4, 1]\tAvg return: 98.651\tTotal loss: 0.043\n",
      "(300/1000) Episode actions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\tAvg return: 98.131\tTotal loss: 0.098\n",
      "(400/1000) Episode actions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\tAvg return: 95.048\tTotal loss: 0.037\n",
      "(500/1000) Episode actions: [4, 4, 4, 1, 1, 4, 1, 4, 1, 1]\tAvg return: 99.049\tTotal loss: 0.044\n",
      "(600/1000) Episode actions: [4, 1, 1, 4, 4, 4, 4, 4, 4, 4]\tAvg return: 96.968\tTotal loss: 0.035\n",
      "(700/1000) Episode actions: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\tAvg return: 98.094\tTotal loss: 0.040\n",
      "(800/1000) Episode actions: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\tAvg return: 96.493\tTotal loss: 0.035\n",
      "(900/1000) Episode actions: [4, 4, 1, 4, 4, 4, 1, 4, 4, 4]\tAvg return: 97.405\tTotal loss: 0.037\n",
      "(1000/1000) \tAvg return: 98.288\tTotal loss: 0.041\n"
     ]
    }
   ],
   "source": [
    "# Train agent\n",
    "agent.train(target_score=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "020e4a44-5431-458c-8f30-7c54c907e2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available. Device set to GPU.\n",
      "Loaded A2C model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.logger.Logger at 0x12d9728e740>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b87e4a0-e60d-4058-a83e-50ce965f499c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agent.logger.env_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3613c95d-c000-4f38-ac47-90371d7f26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gym\n",
    "# from IPython import display\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# from utils.helper import to_tensor, to_numpy, normalize_states\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# %matplotlib inline\n",
    "\n",
    "# env = gym_super_mario_bros.make(ENV_NAME)\n",
    "# env = JoypadSpace(env, RIGHT_ONLY)\n",
    "# env = SkipFrame(env, skip=4)\n",
    "# env = GrayScaleObservation(env, keep_dim=False) # Grayscale images\n",
    "# env = ResizeObservation(env, shape=84) # image dim: [84, 84]\n",
    "# env = FrameStack(env, num_stack=4) # 4 frames at a time\n",
    "\n",
    "# agent.load_model()\n",
    "\n",
    "# state = env.reset()\n",
    "# for _ in range(1000):\n",
    "#     state = normalize_states(to_tensor(state)).to(config.device)\n",
    "#     action_probs = agent.config.network.forward(state.unsqueeze(0))[0]\n",
    "#     action = torch.distributions.Categorical(action_probs).sample().item()\n",
    "#     next_state, reward, done, _ = env.step(action)\n",
    "#     env.render()\n",
    "    \n",
    "#     state = next_state\n",
    "    \n",
    "#     if done:\n",
    "#         state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b979d-2214-46e9-8ad0-b0db80b93f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gym\n",
    "# from IPython import display\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# from utils.helper import to_tensor, to_numpy, normalize_states\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# %matplotlib inline\n",
    "\n",
    "# env = gym_super_mario_bros.make(ENV_NAME)\n",
    "# env = JoypadSpace(env, RIGHT_ONLY)\n",
    "# env = SkipFrame(env, skip=4)\n",
    "# env = GrayScaleObservation(env, keep_dim=False) # Grayscale images\n",
    "# env = ResizeObservation(env, shape=84) # image dim: [84, 84]\n",
    "# env = FrameStack(env, num_stack=4) # 4 frames at a time\n",
    "\n",
    "# agent.load_model()\n",
    "\n",
    "# state = env.reset()\n",
    "# img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "# for _ in range(1000):\n",
    "#     img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "#     display.display(plt.gcf())\n",
    "#     display.clear_output(wait=True)\n",
    "    \n",
    "#     state = normalize_states(to_tensor(state)).to(config.device)\n",
    "#     action_probs = agent.config.network.forward(state.unsqueeze(0))[0]\n",
    "#     action = torch.distributions.Categorical(action_probs).sample().item()\n",
    "#     next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "#     state = next_state\n",
    "    \n",
    "#     if done:\n",
    "#         state = env.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rla2",
   "language": "python",
   "name": "rla2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
