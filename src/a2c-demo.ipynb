{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07431507-7963-404c-b6e1-c8c6a3261e7f",
   "metadata": {},
   "source": [
    "# A2C Demo\n",
    "This notebook focuses on training and testing the Advantage Actor-Critic (A2C) algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edde6b0c-f316-4730-8b8c-b3d9f58fa455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2c.model import ACNetwork\n",
    "from a2c.agent import A2CAgent\n",
    "from utils.config import Config\n",
    "from utils.helper import set_device\n",
    "from utils.logger import Logger\n",
    "\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import RIGHT_ONLY\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3b44f35-ebcd-4272-a02e-092430cf4c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Frazzle\\anaconda3\\envs\\rla2\\lib\\site-packages\\gym\\envs\\registration.py:505: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-v2 is out of date. You should consider upgrading to version `v3` with the environment ID `SuperMarioBros-v3`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available. Device set to GPU.\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters\n",
    "ENV_NAME = 'SuperMarioBros-v0'\n",
    "\n",
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 0.001\n",
    "EPSILON = 1e-3\n",
    "ENTROPY_WEIGHT = 0.01\n",
    "\n",
    "N_STEPS = 4 # TD bootstrapping\n",
    "GRAD_CLIP = 0.1 # Prevents gradients from being too large\n",
    "NUM_EPISODES = 5000\n",
    "\n",
    "# Create environment\n",
    "env = gym_super_mario_bros.make(ENV_NAME)\n",
    "env = JoypadSpace(env, RIGHT_ONLY)\n",
    "\n",
    "# Set config instance\n",
    "config = Config()\n",
    "\n",
    "# Set cuda device\n",
    "device = set_device()\n",
    "\n",
    "# Add core items to config\n",
    "config.add(\n",
    "    env=env,\n",
    "    env_name=ENV_NAME,\n",
    "    gamma=GAMMA,\n",
    "    lr=LEARNING_RATE,\n",
    "    epsilon=EPSILON,\n",
    "    entropy_weight=ENTROPY_WEIGHT,\n",
    "    rollout_size=N_STEPS,\n",
    "    grad_clip=GRAD_CLIP,\n",
    "    device=device,\n",
    "    num_episodes=NUM_EPISODES,\n",
    "    logger=Logger()\n",
    ")\n",
    "\n",
    "# Setup environment parameters\n",
    "config.set_env_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc1be70a-ef84-46cd-8983-dfe7baccd52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available actions: Discrete(5)\n",
      "Obs space shape:  (240, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/Kautenja/gym-super-mario-bros/blob/master/gym_super_mario_bros/actions.py\n",
    "print('Available actions:', config.action_space)\n",
    "print('Obs space shape: ', config.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19b73843-b9ee-40dd-9097-8f937bbe4018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network\n",
    "a2c = ACNetwork(config.input_shape, config.n_actions).to(device)\n",
    "\n",
    "# Add optimizer and network to config\n",
    "config.add(\n",
    "    optimizer_fn=lambda params: optim.Adam(\n",
    "        params,\n",
    "        lr=config.lr,\n",
    "        eps=config.epsilon\n",
    "    ),\n",
    "    network_fn=lambda: a2c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b91a75-fa48-4032-a822-ea70e585c9dc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training with N-Steps: 4\n",
      "(1/5000)\tEpisode actions: [2, 4, 1, 1]\tAvg return: -0.004\tTotal loss: 0.016\n",
      "(100/5000)\tEpisode actions: [0, 1, 0, 0]\tAvg return: 50.845\tTotal loss: -0.233\n",
      "(200/5000)\tEpisode actions: [4, 4, 0, 3]\tAvg return: 51.620\tTotal loss: -0.304\n",
      "(300/5000)\tEpisode actions: [4, 4, 0, 1]\tAvg return: 51.828\tTotal loss: -0.277\n",
      "(400/5000)\tEpisode actions: [4, 2, 3, 2]\tAvg return: 52.199\tTotal loss: -0.295\n",
      "(500/5000)\tEpisode actions: [2, 0, 1, 0]\tAvg return: 53.556\tTotal loss: -0.261\n",
      "(600/5000)\tEpisode actions: [2, 0, 1, 0]\tAvg return: 52.151\tTotal loss: -0.284\n",
      "(700/5000)\tEpisode actions: [3, 1, 4, 1]\tAvg return: 53.867\tTotal loss: -0.278\n",
      "(800/5000)\tEpisode actions: [4, 2, 3, 2]\tAvg return: 56.255\tTotal loss: -0.229\n",
      "(900/5000)\tEpisode actions: [0, 2, 0, 2]\tAvg return: 54.790\tTotal loss: -0.232\n",
      "(1000/5000)\tEpisode actions: [2, 2, 1, 0]\tAvg return: 55.225\tTotal loss: -0.241\n",
      "(1100/5000)\tEpisode actions: [2, 4, 3, 2]\tAvg return: 55.249\tTotal loss: -0.244\n",
      "(1200/5000)\tEpisode actions: [0, 1, 3, 2]\tAvg return: 52.841\tTotal loss: -0.284\n",
      "(1300/5000)\tEpisode actions: [2, 4, 1, 2]\tAvg return: 53.605\tTotal loss: -0.271\n",
      "(1400/5000)\tEpisode actions: [0, 0, 4, 2]\tAvg return: 53.117\tTotal loss: -0.236\n",
      "(1500/5000)\tEpisode actions: [3, 4, 1, 2]\tAvg return: 54.372\tTotal loss: -0.273\n",
      "(1600/5000)\tEpisode actions: [2, 2, 4, 4]\tAvg return: 52.858\tTotal loss: -0.256\n",
      "(1700/5000)\tEpisode actions: [2, 0, 4, 0]\tAvg return: 54.545\tTotal loss: -0.217\n",
      "(1800/5000)\tEpisode actions: [2, 2, 3, 1]\tAvg return: 55.281\tTotal loss: -0.253\n",
      "(1900/5000)\tEpisode actions: [1, 2, 2, 4]\tAvg return: 51.940\tTotal loss: -0.288\n",
      "(2000/5000)\tEpisode actions: [3, 2, 3, 0]\tAvg return: 52.676\tTotal loss: -0.290\n",
      "(2100/5000)\tEpisode actions: [1, 0, 0, 0]\tAvg return: 53.060\tTotal loss: -0.235\n",
      "(2200/5000)\tEpisode actions: [0, 2, 3, 0]\tAvg return: 52.947\tTotal loss: -0.254\n",
      "(2300/5000)\tEpisode actions: [4, 2, 1, 0]\tAvg return: 51.873\tTotal loss: -0.279\n",
      "(2400/5000)\tEpisode actions: [1, 0, 2, 4]\tAvg return: 51.734\tTotal loss: -0.284\n",
      "(2500/5000)\tEpisode actions: [0, 4, 1, 4]\tAvg return: 52.660\tTotal loss: -0.274\n",
      "(2600/5000)\tEpisode actions: [4, 2, 4, 1]\tAvg return: 52.907\tTotal loss: -0.290\n",
      "(2700/5000)\tEpisode actions: [3, 4, 4, 4]\tAvg return: 54.552\tTotal loss: -0.264\n",
      "(2800/5000)\tEpisode actions: [4, 1, 3, 4]\tAvg return: 54.659\tTotal loss: -0.277\n",
      "(2900/5000)\tEpisode actions: [0, 3, 0, 1]\tAvg return: 53.777\tTotal loss: -0.237\n",
      "(3000/5000)\tEpisode actions: [4, 3, 0, 3]\tAvg return: 53.630\tTotal loss: -0.259\n",
      "(3100/5000)\tEpisode actions: [4, 3, 1, 0]\tAvg return: 54.211\tTotal loss: -0.257\n",
      "(3200/5000)\tEpisode actions: [3, 4, 2, 0]\tAvg return: 52.761\tTotal loss: -0.273\n",
      "(3300/5000)\tEpisode actions: [0, 0, 3, 3]\tAvg return: 55.365\tTotal loss: -0.200\n",
      "(3400/5000)\tEpisode actions: [4, 4, 3, 1]\tAvg return: 55.387\tTotal loss: -0.285\n",
      "(3500/5000)\tEpisode actions: [4, 1, 3, 1]\tAvg return: 53.724\tTotal loss: -0.310\n",
      "(3600/5000)\tEpisode actions: [2, 1, 0, 2]\tAvg return: 53.627\tTotal loss: -0.254\n",
      "(3700/5000)\tEpisode actions: [2, 2, 1, 1]\tAvg return: 53.660\tTotal loss: -0.304\n",
      "(3800/5000)\tEpisode actions: [3, 0, 3, 2]\tAvg return: 52.812\tTotal loss: -0.276\n",
      "(3900/5000)\tEpisode actions: [2, 2, 2, 2]\tAvg return: 54.230\tTotal loss: -0.266\n",
      "(4000/5000)\tEpisode actions: [1, 4, 2, 4]\tAvg return: 52.881\tTotal loss: -0.312\n",
      "(4100/5000)\tEpisode actions: [0, 0, 0, 3]\tAvg return: 52.057\tTotal loss: -0.192\n",
      "(4200/5000)\tEpisode actions: [4, 2, 3, 4]\tAvg return: 53.630\tTotal loss: -0.303\n",
      "(4300/5000)\tEpisode actions: [2, 4, 3, 0]\tAvg return: 56.277\tTotal loss: -0.214\n",
      "(4400/5000)\tEpisode actions: [0, 0, 3, 0]\tAvg return: 53.091\tTotal loss: -0.158\n",
      "(4500/5000)\tEpisode actions: [0, 3, 1, 2]\tAvg return: 50.834\tTotal loss: -0.300\n",
      "(4600/5000)\tEpisode actions: [0, 4, 4, 2]\tAvg return: 52.881\tTotal loss: -0.261\n",
      "(4700/5000)\tEpisode actions: [0, 0, 1, 3]\tAvg return: 54.127\tTotal loss: -0.197\n",
      "(4800/5000)\tEpisode actions: [2, 0, 0, 4]\tAvg return: 55.905\tTotal loss: -0.159\n",
      "(4900/5000)\tEpisode actions: [2, 0, 3, 2]\tAvg return: 52.384\tTotal loss: -0.270\n",
      "(4999/5000)\tEpisode actions: [4, 4, 3, 1]\tAvg return: 49.830\tTotal loss: -0.375\n"
     ]
    }
   ],
   "source": [
    "# Train agent\n",
    "agent = A2CAgent(config)\n",
    "agent.train(target_score=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fff40060-682c-484e-bff5-4f1e20d7276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper import to_tensor, to_numpy\n",
    "import numpy as np\n",
    "\n",
    "# Create environment\n",
    "env = gym_super_mario_bros.make(ENV_NAME)\n",
    "env = JoypadSpace(env, RIGHT_ONLY)\n",
    "\n",
    "state = env.reset()\n",
    "for step in range(2000):\n",
    "    action_probs = config.network_fn().forward(to_tensor(state).to(config.device).unsqueeze(0))[0]\n",
    "    action = np.random.choice(action_probs.size(dim=1), p=to_numpy(action_probs).ravel())\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    \n",
    "    state = next_state\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1339e59-a41f-4097-bbaf-6f903279d711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rla2",
   "language": "python",
   "name": "rla2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
