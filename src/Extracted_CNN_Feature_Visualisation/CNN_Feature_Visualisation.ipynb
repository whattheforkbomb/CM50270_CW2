{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e1f006-802d-4325-a74a-3c3f78e31c23",
   "metadata": {},
   "source": [
    "## Creating An Environment With Simple Movement\n",
    "Code adapted from: https://pypi.org/project/gym-super-mario-bros/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd2055f-ea63-42d7-8958-2c5b5fe72a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whiffingj/bin/anaconda3/envs/rl/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can torch see a GPU via cuda? Yes\n"
     ]
    }
   ],
   "source": [
    "# check pytorch & cuda are playing together nicely\n",
    "# Known valid setup is pytorch 1.8.2 LTS (need python <=3.8, >=3.6) & cuda 11.3, at least for wsl2 (Ubuntu 18.04 LTS) w/ Nvidia RTX 3070\n",
    "import torch\n",
    "torch_can_see_cuda_device = torch.cuda.is_available()\n",
    "print(\"Can torch see a GPU via cuda? {}\".format(\"Yes\" if torch_can_see_cuda_device else \"No\"))\n",
    "\n",
    "# Get additional error message if not visible\n",
    "if not torch_can_see_cuda_device:\n",
    "    torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7c0822-1e56-4d8e-904a-db506a7eefe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, RIGHT_ONLY, COMPLEX_MOVEMENT\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common import atari_wrappers\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import os\n",
    "\n",
    "RAW = 0\n",
    "DOWNSAMPLE = 1\n",
    "PIXEL = 2\n",
    "RECTANGLE = 3\n",
    "\n",
    "def create_env(version, action_space):\n",
    "    env = gym_super_mario_bros.make('SuperMarioBros-v{}'.format(version))\n",
    "    env = JoypadSpace(env, action_space)\n",
    "    # Convert to greyscale and downsample to 84x84\n",
    "    return atari_wrappers.AtariWrapper(env, noop_max=5, terminal_on_life_loss=False)\n",
    "    \n",
    "def create_vec_env(version, action_space, n):\n",
    "    return DummyVecEnv([lambda: create_env(version, action_space) for _ in range(n)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786b61e-e884-4882-8d74-ea339b216ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be saved to: /home/whiffingj/dev/uni/CM50270_CW2/src/models/ppo\n",
      "Logs will be saved to: /mnt/e/SMB/ppo/logs\n",
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to /mnt/e/SMB/ppo/logs/tensorboard/PPO_1\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 149    |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 874    |\n",
      "|    total_timesteps | 131072 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2023        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014555465 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.00605     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.15        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3165        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010642258 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.98        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 122         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 4294        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011831834 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 5376        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013673781 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    value_loss           | 52.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 6459        |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017218016 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.1        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 7543       |\n",
      "|    total_timesteps      | 917504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02048206 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.85      |\n",
      "|    explained_variance   | 0.767      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 25.9       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00172   |\n",
      "|    value_loss           | 67.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 8630        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024783872 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.8        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | 0.000617    |\n",
      "|    value_loss           | 65          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 9714        |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029562129 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.1        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | 0.0037      |\n",
      "|    value_loss           | 62.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 10796      |\n",
      "|    total_timesteps      | 1310720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03386358 |\n",
      "|    clip_fraction        | 0.381      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.82      |\n",
      "|    explained_variance   | 0.584      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 30.6       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | 0.00678    |\n",
      "|    value_loss           | 53.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 121         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 11888       |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038633972 |\n",
      "|    clip_fraction        | 0.409       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | 0.00954     |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 121        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 12979      |\n",
      "|    total_timesteps      | 1572864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04138276 |\n",
      "|    clip_fraction        | 0.435      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.79      |\n",
      "|    explained_variance   | 0.556      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 14.4       |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | 0.0104     |\n",
      "|    value_loss           | 55.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 14084       |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045167662 |\n",
      "|    clip_fraction        | 0.441       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | 0.011       |\n",
      "|    value_loss           | 59          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 15225       |\n",
      "|    total_timesteps      | 1835008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047260724 |\n",
      "|    clip_fraction        | 0.445       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | 0.0127      |\n",
      "|    value_loss           | 60.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 119        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 16398      |\n",
      "|    total_timesteps      | 1966080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04942955 |\n",
      "|    clip_fraction        | 0.465      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.7       |\n",
      "|    explained_variance   | 0.686      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.7       |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | 0.0141     |\n",
      "|    value_loss           | 60.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 17549       |\n",
      "|    total_timesteps      | 2097152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059846535 |\n",
      "|    clip_fraction        | 0.488       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.0154      |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 119        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 18690      |\n",
      "|    total_timesteps      | 2228224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06556004 |\n",
      "|    clip_fraction        | 0.517      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.68      |\n",
      "|    explained_variance   | 0.723      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 47.9       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | 0.021      |\n",
      "|    value_loss           | 58         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 19805       |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.066056505 |\n",
      "|    clip_fraction        | 0.507       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.2        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.0186      |\n",
      "|    value_loss           | 60.2        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "training_env = create_vec_env(RECTANGLE, SIMPLE_MOVEMENT, 128)\n",
    "\n",
    "# assuming running in the src dir\n",
    "cwd = os.getcwd()\n",
    "if \"/src\" in cwd:\n",
    "    model_path = \"{}/models/ppo\".format(cwd)\n",
    "else:\n",
    "    model_path = \"{}/src/models/ppo\".format(os.getcwd())\n",
    "print(\"Model will be saved to: {}\".format(model_path))\n",
    "assert os.path.isdir(model_path)\n",
    "\n",
    "# hard-coded to different mount\n",
    "log_path = \"/mnt/e/SMB/ppo/logs\"\n",
    "print(\"Logs will be saved to: {}\".format(log_path))\n",
    "assert os.path.isdir(log_path)\n",
    "\n",
    "# Using Pre-implemented algo\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "total_timesteps = 5e6\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(save_freq=1e6,\n",
    "                                         save_path=log_path,\n",
    "                                         name_prefix='smbv3_model_3')\n",
    "model = PPO(\"CnnPolicy\", training_env, verbose=1, batch_size=64, n_steps=1024, tensorboard_log=\"{}/tensorboard/\".format(log_path))\n",
    "model.learn(total_timesteps=total_timesteps, callback=checkpoint_callback)\n",
    "model.save(\"{}/SuperMarioBrosRandomStages_{}_{}_{}_model_2\".format(model_path, RECTANGLE, \"SIMPLE_MOVEMENT\", \"CnnPolicy\"))\n",
    "\n",
    "training_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b0f9c-4217-4d1c-b865-b5288cc12655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting-up env\n",
      "Loading model from: /home/whiffingj/dev/uni/CM50270_CW2/src/models/ppo/SuperMarioBrosRandomStages_2_RIGHT_ONLY_CnnPolicy_model\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
    "\n",
    "# Viewing what it has managed to learn\n",
    "print(\"setting-up env\")\n",
    "test_env = create_vec_env(PIXEL, RIGHT_ONLY, 1)\n",
    "test_step_limit = 5000\n",
    "model_path = \"{}/src/models/ppo/SuperMarioBrosRandomStages_{}_{}_{}_model\".format(os.getcwd(), PIXEL, \"RIGHT_ONLY\", \"CnnPolicy\")\n",
    "video_path = \"/mnt/e/SMB/ppo/video\"\n",
    "# Make ability to pick model?\n",
    "\n",
    "# if model is None: # if not already defined, load from saved model:\n",
    "assert os.path.isfile(\"{}.zip\".format(model_path))\n",
    "print(\"Loading model from: {}\".format(model_path))\n",
    "model = PPO.load(model_path)\n",
    "assert os.path.isdir(video_path)\n",
    "\n",
    "# save to e drive (/mnt/e/smb_agent_training)\n",
    "print(\"Setting up recorder\")\n",
    "VecVideoRecorder(test_env, video_folder=video_path, record_video_trigger=lambda step: step == 0, video_length=test_step_limit, name_prefix=\"smb_test\")\n",
    "\n",
    "print(\"resetting env\")\n",
    "obs = test_env.reset()\n",
    "for _ in range(test_step_limit):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = test_env.step(action)\n",
    "    test_env.render()\n",
    "    if done:\n",
    "      obs = test_env.reset()\n",
    "\n",
    "test_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9fa021-0a62-40f2-8827-ade3db5324b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case there's an issue with the training/execution, run this to ensure env closed.\n",
    "try:\n",
    "    training_env.close()\n",
    "except Exception as ex:\n",
    "    print(\"training_env already closed / doesn't exist:\\n{}\".format(ex))\n",
    "\n",
    "try:\n",
    "    test_env.close()\n",
    "except Exception as ex:\n",
    "    print(\"test_env already closed / doesn't exist:\\n{}\".format(ex))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
